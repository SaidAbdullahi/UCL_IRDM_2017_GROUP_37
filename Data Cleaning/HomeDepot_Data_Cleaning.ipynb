{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All the necessary libraries\n",
    "import re\n",
    "import nltk\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Spell checkers\n",
    "from spell_check_dict import spelling_checker_dict as spellcheck_dict\n",
    "from google_search import spell_check as spellcheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vinyl grip strip'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predefined spellcheck dictionary\n",
    "spellcheck_dict['vynal grip strip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vinyl'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Live Google spellcheck\n",
    "spellcheck('vinyal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load dataset files into dataframes\n",
    "df_train = pd.read_csv('train.csv', encoding=\"ISO-8859-1\")\n",
    "df_test = pd.read_csv('test.csv', encoding=\"ISO-8859-1\")\n",
    "df_pro_desc = pd.read_csv('product_descriptions.csv')\n",
    "df_attr = pd.read_csv('attributes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dummy dataframes for proof of concept\n",
    "df_train_1 = df_train.copy()\n",
    "df_test_1 = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data cleaning functions start here\n",
    "\n",
    "# helol wold -> hello world\n",
    "# only uses predefined spell check dict atm\n",
    "# we can include google spell check for those not in dict\n",
    "def spellchecker(searchwords):\n",
    "    if searchwords in spellcheck_dict.keys():\n",
    "        return spellcheck_dict[searchwords]\n",
    "    else:\n",
    "        return searchwords\n",
    "\n",
    "# Hello World -> hello world\n",
    "def lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "# process all regexes from other functions below\n",
    "def regex_processor(text, replace_list):\n",
    "    for pattern, replace in replace_list:\n",
    "            try:\n",
    "                text = re.sub(pattern, replace, text)\n",
    "            except:\n",
    "                pass\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip() \n",
    "\n",
    "# 200 wattage, 200 watts, 200 watt -> 200 watt\n",
    "def convertunits(text):\n",
    "    replace_list = [\n",
    "            (r\"([0-9]+)( *)(inches|inch|in|in.|')\\.?\", r\"\\1 in. \"),\n",
    "            (r\"([0-9]+)( *)(pounds|pound|lbs|lb|lb.)\\.?\", r\"\\1 lb. \"),\n",
    "            (r\"([0-9]+)( *)(foot|feet|ft|ft.|'')\\.?\", r\"\\1 ft. \"),\n",
    "            (r\"([0-9]+)( *)(square|sq|sq.) ?\\.?(inches|inch|in|in.|')\\.?\", r\"\\1 sq.in. \"),\n",
    "            (r\"([0-9]+)( *)(square|sq|sq.) ?\\.?(feet|foot|ft|ft.|'')\\.?\", r\"\\1 sq.ft. \"),\n",
    "            (r\"([0-9]+)( *)(cubic|cu|cu.) ?\\.?(inches|inch|in|in.|')\\.?\", r\"\\1 cu.in. \"),\n",
    "            (r\"([0-9]+)( *)(cubic|cu|cu.) ?\\.?(feet|foot|ft|ft.|'')\\.?\", r\"\\1 cu.ft. \"),\n",
    "            (r\"([0-9]+)( *)(gallons|gallon|gal)\\.?\", r\"\\1 gal. \"),\n",
    "            (r\"([0-9]+)( *)(ounces|ounce|oz)\\.?\", r\"\\1 oz. \"),\n",
    "            (r\"([0-9]+)( *)(centimeters|cm)\\.?\", r\"\\1 cm. \"),\n",
    "            (r\"([0-9]+)( *)(milimeters|mm)\\.?\", r\"\\1 mm. \"),\n",
    "            (r\"([0-9]+)( *)(minutes|minute)\\.?\", r\"\\1 min. \"),\n",
    "            (r\"([0-9]+)( *)(Â°|degrees|degree)\\.?\", r\"\\1 deg. \"),\n",
    "            (r\"([0-9]+)( *)(v|volts|volt)\\.?\", r\"\\1 volt. \"),\n",
    "            (r\"([0-9]+)( *)(wattage|watts|watt)\\.?\", r\"\\1 watt. \"),\n",
    "            (r\"([0-9]+)( *)(amperes|ampere|amps|amp)\\.?\", r\"\\1 amp. \"),\n",
    "            (r\"([0-9]+)( *)(qquart|quart)\\.?\", r\"\\1 qt. \"),\n",
    "            (r\"([0-9]+)( *)(hours|hour|hrs.)\\.?\", r\"\\1 hr \"),\n",
    "            (r\"([0-9]+)( *)(gallons per minute|gallon per minute|gal per minute|gallons/min.|gallons/min)\\.?\", r\"\\1 gal. per min. \"),\n",
    "            (r\"([0-9]+)( *)(gallons per hour|gallon per hour|gal per hour|gallons/hour|gallons/hr)\\.?\", r\"\\1 gal. per hr \"),\n",
    "        ]\n",
    "    return regex_processor(text, replace_list)   \n",
    "\n",
    "\n",
    "# helloWorld -> hello World\n",
    "def splitcases(text):\n",
    "    replace_list = [\n",
    "            (r\"(\\w)[\\.?!]([A-Z])\", r\"\\1 \\2\"),\n",
    "            (r\"(?<=( ))([a-z]+)([A-Z]+)\", r\"\\2 \\3\"),\n",
    "        ]\n",
    "    return regex_processor(text, replace_list)   \n",
    "    \n",
    "\n",
    "# hello/world, hello-world -> hello world\n",
    "def removewordsplitters(text):\n",
    "    replace_list = [\n",
    "            (r\"([a-zA-Z]+)[/\\-]([a-zA-Z]+)\", r\"\\1 \\2\"),\n",
    "        ]\n",
    "    return regex_processor(text, replace_list)   \n",
    "    \n",
    "# 1x1 -> 1 x 1\n",
    "def digitsplitters(text):\n",
    "    replace_list = [\n",
    "            (r\"(\\d+)[\\.\\-]*([a-zA-Z]+)\", r\"\\1 \\2\"),\n",
    "            (r\"([a-zA-Z]+)[\\.\\-]*(\\d+)\", r\"\\1 \\2\"),\n",
    "        ]\n",
    "    return regex_processor(text, replace_list)   \n",
    "\n",
    "# 1,000 -> 1000\n",
    "def digitcommaremover(text):\n",
    "    replace_list = [\n",
    "            (r\"([0-9]),([0-9])\", r\"\\1\\2\")\n",
    "    ]\n",
    "    return regex_processor(text, replace_list)   \n",
    "\n",
    "# one -> 1\n",
    "def numberconverter(text):\n",
    "    numbers = [\n",
    "            \"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\", \"ten\",\n",
    "            \"eleven\", \"twelve\", \"thirteen\", \"fourteen\", \"fifteen\", \"sixteen\", \"seventeen\", \"eighteen\",\n",
    "            \"nineteen\", \"twenty\", \"thirty\", \"forty\", \"fifty\", \"sixty\", \"seventy\", \"eighty\", \"ninety\", \"hundred\", \"thousand\"\n",
    "        ]\n",
    "    digits = [\n",
    "        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 140, 15,\n",
    "        16, 17, 18, 19, 20, 30, 40, 50, 60, 70, 80, 90, 100, 1000\n",
    "    ]\n",
    "    replace_list = [\n",
    "        (r\"%s\"%n, str(d)) for n,d in zip(numbers, digits)\n",
    "    ]\n",
    "    return regex_processor(text, replace_list)  \n",
    "\n",
    "# remove special characters\n",
    "def specialcharcleaner(text):\n",
    "    replace_list = [\n",
    "            (r\"<.+?>\", r\"\"),\n",
    "            (r\"&nbsp;\", r\" \"),\n",
    "            (r\"&amp;\", r\"&\"),\n",
    "            (r\"&#39;\", r\"'\"),\n",
    "            (r\"/>/Agt/>\", r\"\"),\n",
    "            (r\"</a<gt/\", r\"\"),\n",
    "            (r\"gt/>\", r\"\"),\n",
    "            (r\"/>\", r\"\"),\n",
    "            (r\"<br\", r\"\"),\n",
    "            (r\"[ &<>)(_,;:!?\\+^~@#\\$]+\", r\" \"),\n",
    "            (\"'s\\\\b\", r\"\"),\n",
    "            (r\"[']+\", r\"\"),\n",
    "            (r\"[\\\"]+\", r\"\"),\n",
    "        ]\n",
    "    return regex_processor(text, replace_list)  \n",
    "\n",
    "# handle all HTML tags\n",
    "def HtmlCleaner(text, parser='html.parser'):\n",
    "    bs = BeautifulSoup(text, parser)\n",
    "    text = bs.get_text(separator=\" \")\n",
    "    return text\n",
    "\n",
    "# lemmatizing\n",
    "def lemmatizer(text):\n",
    "    Tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "    Lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "    tokens = [Lemmatizer.lemmatize(token) for token in Tokenizer.tokenize(text)]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# stemming\n",
    "def stemmer(text):\n",
    "    stemmer = nltk.stem.PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in text.split(\" \")]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Cleaning Train Data---\n",
      " :) Train Data Cleaning Finished in 1.35 minutes\n"
     ]
    }
   ],
   "source": [
    "# Apply all data cleaning\n",
    "\n",
    "def df_cleaner(df_col):\n",
    "    cleaner_funcs = [\n",
    "        spellchecker,\n",
    "        lowercase,\n",
    "        convertunits,\n",
    "        splitcases,\n",
    "        removewordsplitters,\n",
    "        digitsplitters,\n",
    "        digitcommaremover,\n",
    "        numberconverter,\n",
    "        specialcharcleaner,\n",
    "        HtmlCleaner,\n",
    "        lemmatizer,\n",
    "        stemmer\n",
    "    ]\n",
    "    \n",
    "    for func in cleaner_funcs:\n",
    "        df_col = df_col.apply(func)\n",
    "    return df_col\n",
    "\n",
    "start_train_time = time.time()\n",
    "print(\"--- Cleaning Train Data---\")\n",
    "\n",
    "# Clean train data\n",
    "df_train_1.product_title = df_cleaner(df_train_1.product_title)\n",
    "df_train_1.search_term = df_cleaner(df_train_1.search_term)\n",
    "\n",
    "print(\" :) Train Data Cleaning Finished in %s minutes\" % round(((time.time() - start_train_time)/60),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning Test Data\n",
      " :) Test Data Cleaning Finished in 2.9 minutes\n"
     ]
    }
   ],
   "source": [
    "start_test_time = time.time()\n",
    "print(\"Cleaning Test Data\")\n",
    "\n",
    "# Clean test data\n",
    "df_test_1.product_title = df_cleaner(df_test_1.product_title)\n",
    "df_test_1.search_term = df_cleaner(df_test_1.search_term)\n",
    "\n",
    "print(\" :) Test Data Cleaning Finished in %s minutes\" % round(((time.time() - start_test_time)/60),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Repeat data cleaning for extra dataframes / columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    Simpson Strong-Tie 12-Gauge Angle\n",
       "1                    Simpson Strong-Tie 12-Gauge Angle\n",
       "2    BEHR Premium Textured DeckOver 1-gal. #SC-141 ...\n",
       "3    Delta Vero 1-Handle Shower Only Faucet Trim Ki...\n",
       "4    Delta Vero 1-Handle Shower Only Faucet Trim Ki...\n",
       "Name: product_title, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time to check results\n",
    "\n",
    "# Original uncleaned data\n",
    "df_train.product_title[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      simpson strong tie 12 gaug angl\n",
       "1                      simpson strong tie 12 gaug angl\n",
       "2    behr premium textur deckov 1 gal. sc 141 tugbo...\n",
       "3    delta vero 1 handl shower onli faucet trim kit...\n",
       "4    delta vero 1 handl shower onli faucet trim kit...\n",
       "Name: product_title, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaned data\n",
    "df_train_1.product_title[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Testing spell checker\n",
    "# # Apply spell checker to train and test search terms\n",
    "# df_train_1.search_term = df_train_1.search_term.apply(spellchecker)\n",
    "# df_test_1.search_term = df_test_1.search_term.apply(spellchecker)\n",
    "\n",
    "# # No of search terms corrected in Train\n",
    "# train_corrected = list(df_train.search_term.isin(df_train_1.search_term.apply(spellchecker))).count(False)\n",
    "\n",
    "# # No of search terms corrected in Test\n",
    "# test_corrected = list(df_test.search_term.isin(df_test_1.search_term.apply(spellchecker))).count(False)\n",
    "\n",
    "# print(train_corrected, test_corrected)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [python35]",
   "language": "python",
   "name": "Python [python35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
